# -*- coding: utf-8 -*-
"""FINAL_CLEAN_INFERENCE_DIFFERENT_MODELS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ApkrNJzWRIYQsAZsZ147Euh-w2dygg_O
"""

print("--CLEAN INFERENCE DIFFERENT MODELS--")

import os
import sys
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn 
import torch.optim as optim

'''

ALL this training was done on a subset of 17827 of the solid color pills from the dataset.

THE CODE in this notebook illustrats why we chose the pre trained densenet model. In our initial
proposal we had suggested using either vgg16, inceptionv3, or densenet. I was hoping we could
use vgg16 because I had used it in the past and therefore I know how powerful it is. But we were
not able to use it because we didnt have the proper hardware. As the notebook illustrates, 
the code crashed when we tried to train with vgg16, even when freezing the parameters of every 
layer of the model except the last one, which we added. This is becuase our GPU just ran out
of memory. Even when using a 12 gig gpu we could not train on this model. 

The inceptionv3 was good, we were able to load on it and train it. But it just had an accuracy
that was too low. The inception, with all the layers frozen except the last layer, which we 
added, gave us an accuracy of 64.25% after 7 epochs. 

Then we went to the densenet model and froze all of its layers except for 2 linear layers, which
we added. Immediately we noticed validation accuracy was much better. On the validation images
it got up to 82.19% after just 7 epochs. We then took the exact same model, and froze all of the
layers up to layer 300. Training on this model gave us an accuracy of 86.71% after just
7 epochs. 

'''

#!unzip /content/color_sorted_images_training_32_by_32.zip -d /content/color_sorted_images

print("LIST ALL THE PILL IMAGES")

enumerate_images = False

def absoluteFilePaths(directory):
    all_filez = []
    for dirpath,_, filenames in os.walk(directory):
        for f in filenames:
            print(os.path.join(dirpath, f))
            all_filez.append((os.path.join(dirpath, f)))

    return all_filez

if enumerate_images:

  all_original_filez = absoluteFilePaths("/content/color_sorted")

  print("NUMBER OF FILES: " + str(len(all_original_filez)))

print("BUILD DATA LOADER")

import torchvision.transforms as transforms
import torchvision.datasets as datasets

from torch.utils.data import DataLoader, random_split, WeightedRandomSampler

import torch

# batch size
BATCH_SIZE = 32
BATCH_SIZE_VALID = 32

train_path = "/content/color_sorted_images/color_sorted_images_training_32_by_32"
val_path = "/content/color_sorted_images/color_sorted_images_training_32_by_32"

print("TRAINING PATH: " + train_path)
print("VALIDATION PATH: " + val_path)

# the training transforms
train_transform = transforms.Compose([
    #transforms.Resize((32, 32)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    #transforms.ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),
    #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),
    transforms.RandomRotation(degrees=(30, 70)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])
# the validation transforms
valid_transform = transforms.Compose([
    #transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])

# training dataset
train_dataset = datasets.ImageFolder(
    root=train_path,
    transform=train_transform
)
# validation dataset
valid_dataset = datasets.ImageFolder(
    root=val_path,
    transform=valid_transform  #**CAREFUL, CHANGING FOR TESTING!
)



#**BEGIN TESTING RANDOM WEIGHTED SAMPLER

train_length = len(train_dataset)

train_set_size = int(len(train_dataset) * 0.8)
print(train_set_size)
valid_set_size = len(train_dataset) - train_set_size

train_dataset2, valid_dataset2 = random_split(train_dataset, [train_set_size, valid_set_size]) #*just to get the right
                                                                            #struct we need for weighted random sampler
check_train_length = len(train_dataset2)

import numpy as np

y_train_indices = train_dataset2.indices

y_train = [train_dataset.targets[i] for i in y_train_indices]

class_sample_count = np.array(
    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])

weight = 1. / class_sample_count
#weight[7] = weight[7] / 2
#weight[10] = weight[10] / 2
samples_weight = np.array([weight[t] for t in y_train])
samples_weight = torch.from_numpy(samples_weight)

sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))

#**END TESTING, RANDOM WEIGHTED SAMPLER

# training data loaders
train_loader = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, shuffle=True,  #**FOR WEIGHTED SAMPLING, change to sampler=sampler
    num_workers=2, pin_memory=True
)
# validation data loaders
valid_loader = DataLoader(
    valid_dataset2, batch_size=BATCH_SIZE_VALID, shuffle=False,
    num_workers=2, pin_memory=True
)

print("TRAINING DATASET LENGTH: " + str(len(train_loader)))
print("VALIDATION DATASET LENGTH: " + str(len(valid_loader)))

print("--RAW DATASET DISTRIBUTION OF 17827 SOLID COLORS SUBSET--")
import os

all_filez = absoluteFilePaths("/content/color_subset/color_sorted_images_training_32_by_32")

classes = []
classes.append("BLACK")  #**YOU NEED TO MAKE SURE ALL YOUR IMAGE CLASSES IN HERE AND THAT THEY ARE IN ALPHABETICAL ORDER
classes.append("BLUE")
classes.append("BROWN")
classes.append("GRAY")
classes.append("GREEN")
classes.append("ORANGE")
classes.append("PINK")
classes.append("PURPLE")
classes.append("RED")
classes.append("TURQUOISE")
classes.append("WHITE")
classes.append("YELLOW")

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

for da_file in all_filez:
    for idx in classes:
        if idx in da_file:
            tracking_dict[idx] += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')

plt.show()

print("TOTAL NUMBER OF IMAGES: " + str(len(all_filez)))

print("--RAW DATASET DISTRIBUTION OF 58796 SOLID COLORS SUBSET--")

tracking_dict = {'BLACK': 37, 'BLUE': 4605, 'BROWN': 2901, 'GRAY': 304, 'GREEN': 2870, 'ORANGE': 5474, 'PINK': 4860, 'PURPLE': 1020, 'RED': 1685, 'TURQUOISE': 455, 'WHITE': 22468, 'YELLOW': 7146}

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')

plt.show()

#!unzip /content/color_sorted_images_training_32_by_32.zip -d /content/color_subset

print("--DISTRIBUTION OF TRAINING DATASET (17827 subset)--")

def absoluteFilePaths(directory):
    all_filez = []
    for dirpath,_, filenames in os.walk(directory):
        for f in filenames:
            print(os.path.join(dirpath, f))
            all_filez.append((os.path.join(dirpath, f)))

    return all_filez

classes = []
classes.append("BLACK")  #**YOU NEED TO MAKE SURE ALL YOUR IMAGE CLASSES IN HERE AND THAT THEY ARE IN ALPHABETICAL ORDER
classes.append("BLUE")
classes.append("BROWN")
classes.append("GRAY")
classes.append("GREEN")
classes.append("ORANGE")
classes.append("PINK")
classes.append("PURPLE")
classes.append("RED")
classes.append("TURQUOISE")
classes.append("WHITE")
classes.append("YELLOW")

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

total_image_count = 0
for i, data in enumerate(train_loader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1
              total_image_count += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')

plt.show()

print("TOTAL NUMBER OF IMAGES: " + str(total_image_count))

print("--DISTRIBUTION OF VALIDATION DATASET--")

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

total_image_count = 0
for i, data in enumerate(valid_loader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1
              total_image_count += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')

plt.show()

print("TOTAL NUMBER OF IMAGES: " + str(total_image_count))

print("--TRAINING AND VALIDATION LOOPS--")

def save_model(epochs, model, optimizer, criterion, model_path, val_acc="none"):
    """
    Function to save the trained model to disk.
    """
    import random
    extension = random.randint(0,9999999999)
    extension = str(extension) + "_" + str(val_acc) + "_"
    extension = extension + ".all_files"
    model_path = model_path + extension #*add a file extension so we can easily keep savin new models why not?
    print("SAVING COLOR MODEL: " + model_path)
    torch.save({
                'epoch': epochs,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': criterion,
                }, model_path)

def load_model(model, model_path):
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    #ptimizer.load_state_dict[checkpoint['optimizer_state_dict']]
    return model

def validate_it(model):
  ### TESTING PORTION ###
    from timeit import default_timer as timer
    start = timer()
    print("validating model")
    correct = 0
    total = 0
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            # calculate outputs by running images through the network
            images = images.cuda()
            labels = labels.cuda()
            #outputs = model(images)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    acc = correct / total
    print(f'Accuracy of the pytorch model on the validation images: {100*acc:.2f}%')
    end = timer()
    print(end - start) # Time in seconds, e.g. 5.38091952400282
    return acc

train_loder = train_loader
test_loader = valid_loader

def pytorch_train_and_evaluate(model, train_loader, test_loader, epoch_num = 5):
    ### TRAINING PORTION ###
    from timeit import default_timer as timer
    start = timer()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    #model.cuda()
    print("perform initial validation check: ")
    val_acc = validate_it(model)
    print("perform model save check: ")
    save_model(0, model, optimizer, criterion, "/content/model.pth", val_acc=val_acc)
    #print("perform initial validation check: ")
    #validate_it(model)
    for epoch in range(epoch_num):  # loop over the dataset multiple times
        print("TRAINING EPOCH: " + str(epoch))
        #validate_it(model)
        running_loss = 0.0
        start = timer()
        for i, data in enumerate(train_loader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            inputs = inputs.to('cuda')
            labels = labels.to('cuda')

            # zero the parameter gradients
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            if i % 100 == 99:    # print every 2000 mini-batches
                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
                running_loss = 0.0
        val_acc = validate_it(model) #*validate after each epoch
        save_model(epoch, model, optimizer, criterion, "/content/model.pth", val_acc=val_acc)
        end = timer()
        print("EPOCH TIME")
        print("Seconds: " + str(end - start)) # Time in seconds, e.g. 5.38091952400282
    validate_it(model)
    save_model(epoch, model, optimizer, criterion, "/content/model.pth")

import gc
gc.collect()

with torch.no_grad():
    torch.cuda.empty_cache()

torch.cuda.empty_cache()

load_previous_model = False #**keep FALSE to train from scratch. TRUE to load a model from disk
previous_model_name = "/content/densenetmodel.pth4737049413.all_files"

print("--DO ACTUAL TRAINING HERE--")

print("--VGG16 TRAINING, ALL MODEL FROZEN EXCEPT LAST LAYER, 8 EPOCHS--")

def define_pytorch_model():
  torch.cuda.empty_cache()
  use_pretrained = True
  from torchvision import models, transforms
  net = models.vgg16(pretrained=use_pretrained)
  for child in net.children():   #**freeze all existing layers, well just train the new linear layer
    for param in child.parameters():
        param.requires_grad = False
  net.classifier[6] = nn.Linear(in_features=4096, out_features=12)
  net.train()
  net.cuda()
  print(net)
  return net

vgg16_pretrained_model = define_pytorch_model()
pytorch_train_and_evaluate(vgg16_pretrained_model, train_loader, test_loader, epoch_num=8)

print("--TRAINING BELOW ON PRETRAINED INCEPTION V3 WITH ALL LAYERS FORZEN EXCEPT LAST 2--")

def define_pytorch_model():
  torch.cuda.empty_cache()
  use_pretrained = True
  from torchvision import models, transforms
  model = models.inception_v3(pretrained=use_pretrained)
  for child in model.children():   #**freeze all existing layers, well just train the 2 new linear layers
    for param in child.parameters():
        param.requires_grad = False
  model.AuxLogits.fc = nn.Linear(768, 12)
  model.fc = nn.Linear(2048, 12)
  model.train()
  model.cuda()
  return model

inception_pretrained_model = define_pytorch_model()
pytorch_train_and_evaluate(inception_pretrained_model, train_loader, test_loader, epoch_num=8)

print("--THIS TRAINING SESSION IS ON DENSNET, ALL LAYERS FROZEN EXCEPT LAST ONE--")

def define_pytorch_model(): #*only LAST LINEAR layer not frozen
  torch.cuda.empty_cache()
  use_pretrained = True
  from torchvision import models, transforms
  model = models.densenet121(pretrained=use_pretrained)
  for child in model.children():   #**freeze all existing layers, well just train the 2 new linear layers
    for param in child.parameters():
        param.requires_grad = False
  num_ftrs = model.classifier.in_features
  model.classifier = nn.Linear(num_ftrs, 12)
  model.train()
  model.cuda()
  return model

densenet_pretrained_model = define_pytorch_model()
pytorch_train_and_evaluate(densenet_pretrained_model, train_loader, test_loader, epoch_num=8)

print("--THIS TRAINING SESSION IS ON DENSNET, ONLY LAYERS UP TO 300 FROZEN--")

def define_pytorch_model(): #**most of model frozen, up to 300 layers,might take long to train
    torch.cuda.empty_cache()
    use_pretrained = True
    from torchvision import models, transforms
    model = models.densenet121(pretrained=use_pretrained)
    total_layers = 0
    for child in model.children():  # **freeze all existing layers, well just train the 2 new linear layers
        for param in child.parameters():
            total_layers += 1
            if total_layers <= 300: #**well freeze most of the model due to training time too long
                param.requires_grad = False
    num_ftrs = model.classifier.in_features
    model.classifier = nn.Linear(num_ftrs, 12)
    model.train()
    model.cuda()
    print("DENSET, FIRST 300 LAYERS FROZEN")
    return model


densenet_pretrained_model = define_pytorch_model()
pytorch_train_and_evaluate(densenet_pretrained_model, train_loader, test_loader, epoch_num=8)

print("--THIS TRAINING SESSION IS ON DENSNET, ONLY LAYERS UP TO 300 FROZEN--")
print("--WEIGHTED RANDOM SAMPLER ENABLED IN THIS TEST. SAME DATASET AND VALIDATION DATA AS ABOVE--")

# training data loaders
train_loader = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, sampler=sampler,  #**FOR WEIGHTED SAMPLING, change to sampler=sampler
    num_workers=2, pin_memory=True
)
# validation data loaders
valid_loader = DataLoader(
    valid_dataset2, batch_size=BATCH_SIZE_VALID, shuffle=False,
    num_workers=2, pin_memory=True
)

def define_pytorch_model(): #**most of model frozen, up to 300 layers,might take long to train
    torch.cuda.empty_cache()
    use_pretrained = True
    from torchvision import models, transforms
    model = models.densenet121(pretrained=use_pretrained)
    total_layers = 0
    for child in model.children():  # **freeze all existing layers, well just train the 2 new linear layers
        for param in child.parameters():
            total_layers += 1
            if total_layers <= 300: #**well freeze most of the model due to training time too long
                param.requires_grad = False
    num_ftrs = model.classifier.in_features
    model.classifier = nn.Linear(num_ftrs, 12)
    model.train()
    model.cuda()
    print("DENSET, FIRST 300 LAYERS FROZEN")
    return model


densenet_pretrained_model = define_pytorch_model()
pytorch_train_and_evaluate(densenet_pretrained_model, train_loader, valid_loader, epoch_num=8)

print("--PLOTTEN CORRECT DENSENET PREDICTIONS, WITH RANDOM WEIGHTED SAMPLER TURNED ON--")

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

def validate_it(model):
    total_images = 0
    total_images_correct_predict = 0
  ### TESTING PORTION ###
    from timeit import default_timer as timer
    start = timer()
    print("validating model")
    correct = 0
    total = 0
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            # calculate outputs by running images through the network
            images = images.cuda()
            labels = labels.cuda()
            #outputs = model(images)
            outputs = model(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            throttle = 0
            for idx in labels:
                total_images += 1
                temp_prediction = predicted[throttle]
                pred = temp_prediction.item()
                real_label = idx.item()
                if real_label == pred:
                    chosen_class = classes[real_label]
                    tracking_dict[chosen_class] += 1
                    total_images_correct_predict += 1
                throttle += 1
            #del images
            #del labels
            #images.detach()
            #labels.detach()
    acc = correct / total
    print(f'Accuracy of the pytorch model on the validation images: {100*acc:.2f}%')
    #print('Training Complete')
    end = timer()
    print(end - start) # Time in seconds, e.g. 5.38091952400282
    print("TOTAL IMAGES: " + str(total_images))
    print("TOTAL IMAGES CORRECTLY PREDICTED: " + str(total_images_correct_predict))
    return acc

validate_it(densenet_pretrained_model)

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()

print("--THIS TRAINING ALEXNET IS ON ALEXNET, ALL LAYERS FROZEN EXCEPT LAST 2--")

def define_pytorch_model(): #**most of model frozen, up to 300 layers,might take long to train
    torch.cuda.empty_cache()
    AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)
    for child in AlexNet_model.children():   #**freeze all existing layers, well just train the 2 new linear layers
      for param in child.parameters():
          param.requires_grad = False
    AlexNet_model.classifier[4] = nn.Linear(4096,1024)
    AlexNet_model.classifier[6] = nn.Linear(1024,12)
    AlexNet_model.cuda()
    return AlexNet_model

AlexNet_model = define_pytorch_model()
pytorch_train_and_evaluate(AlexNet_model, train_loader, test_loader, epoch_num=8)

print("--VALIDATION ON PREVIOUS 88.70% DENSENET MODEL PLOTTED BY COLOR CORRECTLY PREDICTED--")

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

def validate_it(model):
    total_images = 0
    total_images_correct_predict = 0
  ### TESTING PORTION ###
    from timeit import default_timer as timer
    start = timer()
    print("validating model")
    correct = 0
    total = 0
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            # calculate outputs by running images through the network
            images = images.cuda()
            labels = labels.cuda()
            #outputs = model(images)
            outputs = model(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            throttle = 0
            for idx in labels:
                total_images += 1
                temp_prediction = predicted[throttle]
                pred = temp_prediction.item()
                real_label = idx.item()
                if real_label == pred:
                    chosen_class = classes[real_label]
                    tracking_dict[chosen_class] += 1
                    total_images_correct_predict += 1
                throttle += 1
            #del images
            #del labels
            #images.detach()
            #labels.detach()
    acc = correct / total
    print(f'Accuracy of the pytorch model on the validation images: {100*acc:.2f}%')
    #print('Training Complete')
    end = timer()
    print(end - start) # Time in seconds, e.g. 5.38091952400282
    print("TOTAL IMAGES: " + str(total_images))
    print("TOTAL IMAGES CORRECTLY PREDICTED: " + str(total_images_correct_predict))
    return acc

validate_it(densenet_pretrained_model)

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()