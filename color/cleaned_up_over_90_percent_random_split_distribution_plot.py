# -*- coding: utf-8 -*-
"""CLEANED_UP_Over_90_percent_random_split_distribution_plot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1isWvc4V3iwSi_rqS1taBHWyYgQgEvPzQ
"""

import os
import sys

print("WERE GOING TO BARCHART THE COLOR DISRTIBUTION")
print("ALSO THE RANDOM WEIGHTED DATALOADER VS STANDARD DATALOADER")

from google.colab import drive
#drive.mount('/content/drive')

#os.chdir("/content/drive/MyDrive")

!unzip /content/color_sorted_images_training_32_by_32.zip -d /content/color_sorted

print("LIST ALL THE PILL IMAGES")

enumerate_images = True

def absoluteFilePaths(directory):
    all_filez = []
    for dirpath,_, filenames in os.walk(directory):
        for f in filenames:
            print(os.path.join(dirpath, f))
            all_filez.append((os.path.join(dirpath, f)))

    return all_filez

if enumerate_images:

  all_original_filez = absoluteFilePaths("/content/color_sorted")

  print("NUMBER OF FILES: " + str(len(all_original_filez)))

print("BUILD DATA LOADER")

import torchvision.transforms as transforms
import torchvision.datasets as datasets

from torch.utils.data import DataLoader, random_split, WeightedRandomSampler

import torch

# batch size
BATCH_SIZE = 32
BATCH_SIZE_VALID = 32

train_path = "/content/color_sorted/color_sorted_images_training_32_by_32"
val_path = "/content/color_sorted/color_sorted_images_training_32_by_32"

print("TRAINING PATH: " + train_path)
print("VALIDATION PATH: " + val_path)

# the training transforms
train_transform = transforms.Compose([
    #transforms.Resize((32, 32)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    #transforms.ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),
    #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),
    transforms.RandomRotation(degrees=(30, 70)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])
# the validation transforms
valid_transform = transforms.Compose([
    #transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])

# training dataset
train_dataset = datasets.ImageFolder(
    root=train_path,
    transform=train_transform
)
# validation dataset
valid_dataset = datasets.ImageFolder(
    root=val_path,
    transform=valid_transform  #**CAREFUL, CHANGING FOR TESTING!
)



#**BEGIN TESTING RANDOM WEIGHTED SAMPLER

train_length = len(train_dataset)

print("DEBUG: ")
print(str(train_length))

train_set_size = int(len(train_dataset) * 0.8)
print(train_set_size)
valid_set_size = len(train_dataset) - train_set_size

train_dataset2, valid_dataset2 = random_split(train_dataset, [train_set_size, valid_set_size]) #*just to get the right
                                                                            #struct we need for weighted random sampler
check_train_length = len(train_dataset2)

import numpy as np

y_train_indices = train_dataset2.indices

y_train = [train_dataset.targets[i] for i in y_train_indices]

class_sample_count = np.array(
    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])

weight = 1. / class_sample_count
#weight[7] = weight[7] / 2
#weight[10] = weight[10] / 2
samples_weight = np.array([weight[t] for t in y_train])
samples_weight = torch.from_numpy(samples_weight)

sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))

#**END TESTING, RANDOM WEIGHTED SAMPLER

# training data loaders
train_loader = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, shuffle=True,  #**to use random sweight sampler change shuffle=true to sampler=sampler
    num_workers=2, pin_memory=True
)
# validation data loaders
valid_loader = DataLoader(
    valid_dataset2, batch_size=BATCH_SIZE_VALID, shuffle=False,
    num_workers=2, pin_memory=True
)

print("TRAINING DATASET LENGTH: " + str(len(train_loader)))
print("VALIDATION DATASET LENGTH: " + str(len(valid_loader)))

print("Plot the Distribution of the data loader for research purposes")

print("PRINT WITHOUT SHUFFLING OR WEIGTED RANDOM SAMPLER")
# training data loaders
train_loader_plot = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, shuffle=False,
    num_workers=0, pin_memory=True
)

classes = []
classes.append("BLACK")  #**YOU NEED TO MAKE SURE ALL YOUR IMAGE CLASSES IN HERE AND THAT THEY ARE IN ALPHABETICAL ORDER
classes.append("BLUE")
classes.append("BROWN")
classes.append("GRAY")
classes.append("GREEN")
classes.append("ORANGE")
classes.append("PINK")
classes.append("PURPLE")
classes.append("RED")
classes.append("TURQUOISE")
classes.append("WHITE")
classes.append("YELLOW")

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

throttle = 0
for i, data in enumerate(train_loader_plot, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            if throttle == 10:
              break
            throttle += 1
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()

print("ALL the batches in the training set, without weighted sampler or shuffle")

# training data loaders
train_loader_plot = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, shuffle=False,
    num_workers=0, pin_memory=True
)

throttle = 0
for i, data in enumerate(train_loader_plot, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            throttle += 1
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()

print("PRINT WITH SHUFFLE")

# training data loaders
train_loader_plot = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, shuffle=True,
    num_workers=0, pin_memory=True
)

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

throttle = 0
for i, data in enumerate(train_loader_plot, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            if throttle == 10:
              break
            throttle += 1
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()

print("PRINT WITH WEIGHTED RANDOM SAMPLER")

# training data loaders
train_loader_plot = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, sampler=sampler,
    num_workers=0, pin_memory=True
)

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

throttle = 0
for i, data in enumerate(train_loader_plot, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            if throttle == 10:
              break
            throttle += 1
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()

print("--PLOTTED INFERENCES USING splimage_split_square_front_sort.zip--")

print("--WE NEED TO CALCULATE ACCURACY AND ALSO PLOT DISTRIBUTION OF CORRECT PREDICTIONS--")

print("BUILD DATA LOADER")

import torchvision.transforms as transforms
import torchvision.datasets as datasets

from torch.utils.data import DataLoader, random_split, WeightedRandomSampler

import torch


#!unzip /content/splimage_split_square_front_sort.zip -d /content/splimage_split_square_front_sort

#**JUST BUILD SIMPLE DATA LOADER FOR JUST THIS 

classes = []
classes.append("BLACK")  #**YOU NEED TO MAKE SURE ALL YOUR IMAGE CLASSES IN HERE AND THAT THEY ARE IN ALPHABETICAL ORDER
classes.append("BLUE")
classes.append("BROWN")
classes.append("GRAY")
classes.append("GREEN")
classes.append("ORANGE")
classes.append("PINK")
classes.append("PURPLE")
classes.append("RED")
classes.append("TURQUOISE")
classes.append("WHITE")
classes.append("YELLOW")

BATCH_SIZE_VALID = 32
custom_val_path = "/content/splimage_split_square_front_sort/splimage_split_square_front_sort"
print("VALIDATION PATH: " + custom_val_path)

# the validation transforms
custom_valid_transform = transforms.Compose([
    transforms.Resize((450,600)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])

# validation dataset
valid_dataset = datasets.ImageFolder(
    root=custom_val_path,
    transform=custom_valid_transform  
)

print("VALIDATION DATASET LENGTH: " + str(len(valid_dataset)))

# training data loaders
train_loader_plot = DataLoader(
    train_dataset2, batch_size=BATCH_SIZE, sampler=sampler,
    num_workers=0, pin_memory=True
)

tracking_dict = {}

for idx in classes: #*initialize the counting
    tracking_dict[idx] = 0

throttle = 0
for i, data in enumerate(train_loader_plot, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            #if throttle == 10:
            #  break
            throttle += 1
            for idx in labels:
              da_label = idx.item()
              chosen_class = classes[da_label]
              #print(chosen_class)
              tracking_dict[chosen_class] += 1

print(tracking_dict)

import matplotlib.pyplot as plt

D = tracking_dict

plt.bar(range(len(D)), list(D.values()), align='center')
plt.xticks(range(len(D)), list(D.keys()))
plt.xticks(rotation=40, ha='right')
# # for python 2.x:
# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x
# plt.xticks(range(len(D)), D.keys())  # in python 2.x

plt.show()

print("--GET THE MODEL TO LEARN IT--")

# pytorch libraries
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn 
import torch.optim as optim

def define_pytorch_model(): #**most of model frozen, up to 300 layers,might take long to train
    torch.cuda.empty_cache()
    use_pretrained = True
    from torchvision import models, transforms
    model = models.densenet121(pretrained=use_pretrained)
    total_layers = 0
    for child in model.children():  # **freeze all existing layers, well just train the 2 new linear layers
        for param in child.parameters():
            total_layers += 1
            if total_layers <= 300: #**well freeze most of the model due to training time too long
                param.requires_grad = False
    num_ftrs = model.classifier.in_features
    model.classifier = nn.Linear(num_ftrs, 12)
    model.train()
    model.cuda()
    print("DENSET, FIRST 300 LAYERS FROZEN")
    return model

#define_pytorch_model()

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize

import psutil
import humanize
import os
import GPUtil as GPU

#device = torch.cuda.get_current_device() 
#device.reset()
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isn’t guaranteed
gpu = GPUs[0]
def printm():
    process = psutil.Process(os.getpid())
    print("Gen RAM Free: " + humanize.naturalsize(psutil.virtual_memory().available), " |     Proc size: " + humanize.naturalsize(process.memory_info().rss))
    print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

def save_model(epochs, model, optimizer, criterion, model_path, val_acc="none"):
    """
    Function to save the trained model to disk.
    """
    import random
    extension = random.randint(0,9999999999)
    extension = str(extension) + "_" + str(val_acc) + "_"
    extension = extension + ".all_files"
    model_path = model_path + extension #*add a file extension so we can easily keep savin new models why not?
    print("SAVING COLOR MODEL: " + model_path)
    torch.save({
                'epoch': epochs,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': criterion,
                }, model_path)

def load_model(model, model_path):
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    #ptimizer.load_state_dict[checkpoint['optimizer_state_dict']]
    return model


print("--DENSENET TRAIN VALIDATE--")

def validate_it(model):
  ### TESTING PORTION ###
    from timeit import default_timer as timer
    start = timer()
    print("validating model")
    correct = 0
    total = 0
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            # calculate outputs by running images through the network
            images = images.cuda()
            labels = labels.cuda()
            #outputs = model(images)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    acc = correct / total
    print(f'Accuracy of the pytorch model on the validation images: {100*acc:.2f}%')
    end = timer()
    print(end - start) # Time in seconds, e.g. 5.38091952400282
    return acc

train_loder = train_loader
test_loader = valid_loader

def pytorch_train_and_evaluate(model, train_loader, test_loader, epoch_num = 5):
    ### TRAINING PORTION ###
    from timeit import default_timer as timer
    start = timer()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    #model.cuda()
    print("perform initial validation check: ")
    val_acc = validate_it(model)
    print("perform model save check: ")
    save_model(0, model, optimizer, criterion, "/content/model.pth", val_acc=val_acc)
    #print("perform initial validation check: ")
    #validate_it(model)
    for epoch in range(epoch_num):  # loop over the dataset multiple times
        print("TRAINING EPOCH: " + str(epoch))
        #validate_it(model)
        running_loss = 0.0
        start = timer()
        for i, data in enumerate(train_loader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data
            inputs = inputs.to('cuda')
            labels = labels.to('cuda')

            # zero the parameter gradients
            optimizer.zero_grad()
            outputs = model(inputs)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            if i % 100 == 99:    # print every 2000 mini-batches
                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
                running_loss = 0.0
        val_acc = validate_it(model) #*validate after each epoch
        save_model(epoch, model, optimizer, criterion, "/content/model.pth", val_acc=val_acc)
        end = timer()
        print("EPOCH TIME")
        print("Seconds: " + str(end - start)) # Time in seconds, e.g. 5.38091952400282
    validate_it(model)
    save_model(epoch, model, optimizer, criterion, "/content/model.pth")

import gc
gc.collect()

with torch.no_grad():
    torch.cuda.empty_cache()

torch.cuda.empty_cache()

load_previous_model = False
previous_model_name = "/content/densenetmodel.pth4737049413.all_files"

if __name__ == "__main__":
    if load_previous_model:
        model = define_pytorch_model()
        model = load_model(model, previous_model_name)
        print("LOADED MODEL: " + previous_model_name)
    else:
        model = define_pytorch_model()
    pytorch_train_and_evaluate(model, train_loader, test_loader, epoch_num=10)

print("LETS TRY TO DO SOME INFERENCES")
print("--INFERENCE SKELETON CODE--")

import torchvision.transforms as transforms
from PIL import Image
import torch
import torch.nn as nn
#import pretrainedmodels as pm

color_model_path = "model.pth9790592595_0.8320246775098149_.all_files"
color_model_path = "/content/model.pth5745821318_0.9032529444756029_.all_files"

classes = []
classes.append("BLACK")  #**YOU NEED TO MAKE SURE ALL YOUR IMAGE CLASSES IN HERE AND THAT THEY ARE IN ALPHABETICAL ORDER
classes.append("BLUE")
classes.append("BROWN")
classes.append("GRAY")
classes.append("GREEN")
classes.append("ORANGE")
classes.append("PINK")
classes.append("PURPLE")
classes.append("RED")
classes.append("TURQUOISE")
classes.append("WHITE")
classes.append("YELLOW")

def load_model(model, model_path):
   checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
   model.load_state_dict(checkpoint['model_state_dict'])
   # ptimizer.load_state_dict[checkpoint['optimizer_state_dict']]
   return model

def pre_image(image_path,model):
   from PIL import Image
   img = Image.open(image_path)
   img_normalized = valid_transform(img).float()
   img_normalized = img_normalized.unsqueeze_(0)
   # input = Variable(image_tensor)
   img_normalized = img_normalized.to("cpu")
   # print(img_normalized.shape)
   with torch.no_grad():
      model.eval()
      output =model(img_normalized)  #*were actually pushing the image through that model here, its a NUMPY ARRAY

      sm = torch.nn.Softmax()
      probabilities = sm(output)
      #print(probabilities)  # Converted to probabilities
      top_p, top_class = probabilities.topk(2, dim=1)
      t1 = top_p[0][0].item()
      t2 = top_p[0][1].item()
      tc1 = top_class[0][0].item()
      tc2 = top_class[0][1].item()
      p1 = t1 * 100
      p2 = t2 * 100
      class_name = classes[tc1]
      second_running_class_name = classes[tc2]
      #return index, class_name #*return the model number label prediction!
      return class_name + " Probability: " + str(p1) + "-- " + second_running_class_name + " Probability: " + str(p2)


# the validation transforms
valid_transform = transforms.Compose([
    #transforms.Resize((450,600)),  #*resize for the color classes
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])

def define_pytorch_model():
  torch.cuda.empty_cache()
  use_pretrained = True
  from torchvision import models, transforms
  model = models.densenet121(pretrained=use_pretrained)
  for child in model.children():   #**freeze all existing layers, well just train the 2 new linear layers
    for param in child.parameters():
        param.requires_grad = False
  num_ftrs = model.classifier.in_features
  model.classifier = nn.Linear(num_ftrs, 12)
  #model.train()
  #model.cuda()
  return model

model = define_pytorch_model()

saved_model_path = color_model_path #*we can more easily set this at the top of the script!
model = load_model(model, saved_model_path)

print("---COLOR MODEL LOADED---")
model.eval()
print(model)

import matplotlib.pyplot as plt 
from IPython.display import Image
from IPython.display import display

def absoluteFilePaths(directory):
    all_filez = []
    for dirpath,_, filenames in os.walk(directory):
        for f in filenames:
            all_filez.append((os.path.join(dirpath, f)))

    return all_filez

red_path = "/content/RED"

images = absoluteFilePaths(red_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=300, height = 300)
    display(x)

white_path = "/content/WHITE"

images = absoluteFilePaths(white_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=300, height = 300)
    display(x)

blue_path = "/content/BLUE"

images = absoluteFilePaths(blue_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

pink_path = "/content/PINK"

images = absoluteFilePaths(pink_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

yellow_path = "/content/YELLOW"

images = absoluteFilePaths(yellow_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

green_path = "/content/GREEN"

images = absoluteFilePaths(green_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

purple_path = "/content/PURPLE"

images = absoluteFilePaths(purple_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

brown_path = "/content/BROWN"

images = absoluteFilePaths(brown_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

green_path = "/content/GREEN"

images = absoluteFilePaths(green_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)

turquoise_path = "/content/TURQUOISE"

images = absoluteFilePaths(turquoise_path)

for ima in images:
    top_two_predictions = pre_image(ima,model)
    print(top_two_predictions)
    x = Image(ima, width=200, height = 200)
    display(x)